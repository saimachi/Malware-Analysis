import base64
import binascii
import re
import csv
import sys
import git

pattern1 = re.compile(r'\$[0Oo]+[{=]')
pattern2 = re.compile(r'\$__=\$__.')
pattern3 = re.compile(r'base64_decode[\s\(]')
pattern4 = re.compile(r'/\*[a-z0-9]+\*/') #/*6g33*/ pattern 
pattern5 = re.compile(r'eval[\s\(]')
pattern6 = re.compile(r'^[A-Za-z0-9]+$') #Jumbled letters and numbers only in the entire line
pattern7 = re.compile(r'my_sucuri_encoding') # Legit sucuri file that look slike bad file
pattern8 = re.compile(r'\'.\'=>\'.\'') # Array map obfus
pattern9 = re.compile(r'chr\([0-9]+\)') # int to ascii
pattern15 = re.compile(r'\$[li]+[{=]')

def list_paths(root_tree, path=''):
    """
    Recursively iterate the files in a commit tree.

    Parameters
    ----------
    root_tree : git.objects.tree.Tree
    path : str
        Starting path for the iteration

    Returns
    -------
    Iterator[str]
    """
    for blob in root_tree.blobs:
        yield blob.name if path == '' else f'{path}/{blob.name}'
    for tree in root_tree.trees:
        yield from list_paths(tree, tree.name if path == '' else f'{path}/{tree.name}')

def decode_file(path):
    """
    Decode a Base-64-encoded file.

    The file will be written to the source directory with the suffix '.decoded'.

    Any lines that cannot be decoded are written as-is.

    Parameters
    ----------
    path : str

    Returns
    -------
    str : Location of the decoded file
    """
    output_path = f'{path}.decoded'
    with open(path, 'rb') as infile, open(output_path, 'wb') as outfile:
        for line in infile.readlines():
            try:
                decoded = base64.b64decode(line)
            except binascii.Error:
                outfile.write(line)
            else:
                try:
                    outfile.write(decoded)
                except UnicodeDecodeError:
                    outfile.write(line)
    return output_path

def main():
    if len(sys.argv) == 1:
        print('Repository path required')
        return
    directory_path = sys.argv[1]
    repo = git.Repo(directory_path)
    # Ensure that iteration doesn't begin from a detached HEAD
    repo.git.execute(['git', 'checkout', 'master'])
    repo.git.execute(['git', 'reset', '--hard', 'HEAD'])
    # CSV output
    rows = []
    # list[set] used to determine files common to all commits
    file_names_all_commits = []
    for commit in repo.iter_commits(reverse=True):
        repo.git.checkout(commit.hexsha)
        print(f'Commit: {commit.hexsha}')
        file_names = set()
        for file_path in list_paths(commit.tree, directory_path):
            file_names.add(file_path)
            output_path = decode_file(file_path)
            with open(output_path, 'r', encoding='ISO-8859-1') as file:
                # Code borrowed from CyFI YODA
                r_data = file.read()
                p1 = re.findall(pattern1, r_data)
                p2 = re.findall(pattern2, r_data)
                p3 = re.findall(pattern3, r_data)
                p4 = re.findall(pattern4, r_data)
                p5 = re.findall(pattern5, r_data)
                p6 = re.findall(pattern6, r_data)
                p7 = re.findall(pattern7, r_data)
                p8 = re.findall(pattern8, r_data)
                p9 = re.findall(pattern9, r_data)
                p15 = re.findall(pattern15, r_data)
                susp = False
                p10=None
                p11=None
                p14=None
                if len(p9) > 15 or p3 or (p3 and p5) or p15:
                    comment_block = False
                    for current_line in file.readlines():
                        current_line = current_line.strip('\n').strip()
                        if comment_block == True:
                            if '*/' not in current_line:
                                continue
                            elif current_line.endswith('*/'):
                                comment_block = False
                                continue
                            elif '*/' in current_line:
                                comment_block = False

                        # Single line comments
                        if current_line.startswith('#') or current_line.startswith('//'):
                            continue
                        if current_line.startswith('/*') and current_line.endswith('*/'):
                            continue
                        # Multiline comment
                        if current_line.startswith('/*') and '*/' not in current_line:
                            comment_block = True
                            continue
                        p10 = re.findall(pattern9, current_line)
                        # Find base64_decde in line
                        p11 = re.findall(pattern3, current_line) #base64_decode
                        p14 = re.findall(pattern5, current_line) #eval
                        p15 = re.findall(pattern15, current_line)
                        if p11 and len(current_line) > 700:
                            susp = True 
                            break
                        if len(p15)>10 and len(current_line) > 1000:
                            susp = True 
                            break

                        if len(p10) > 15:
                            susp = True
                            break
                        if p11 and p14:
                            susp = True
                            break

                # Test this p1 tested. Test the others
                if (len(p1) > 10) or (len(p2) > 10) or  (p3 and p4 and p5) or (len(p8)>10) or (susp) or (len(p4)>15) or len(p15)>10:
                    rows.append([commit.hexsha, file_path])
                elif p6:
                    if ((len(p6[0]) > 25) and (len(p6) > 30 ) and (len(p5)>0) and (len(p7)==0)):
                        rows.append([commit.hexsha, file_path])
        # Remove decoded files
        repo.git.execute(['git', 'clean', '-fx'])
        file_names_all_commits.append(file_names)

    with open('result.csv', 'w') as result:
        writer = csv.writer(result)
        writer.writerow(['Commit', 'File'])
        writer.writerows(rows)
    
    flagged_files = [row[1] for row in rows]
    with open('candidates.txt', 'w') as outfile:
        for common_file in set.intersection(*file_names_all_commits):
            if common_file in flagged_files:
                outfile.write(common_file + '\n')

if __name__ == '__main__':
    main()
