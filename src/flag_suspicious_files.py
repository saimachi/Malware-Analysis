import base64
import binascii
import re
import csv
import git

pattern1 = re.compile(r'\$[0Oo]+[{=]')
pattern2 = re.compile(r'\$__=\$__.')
pattern3 = re.compile(r'base64_decode[\s\(]')
pattern4 = re.compile(r'/\*[a-z0-9]+\*/') #/*6g33*/ pattern 
pattern5 = re.compile(r'eval[\s\(]')
pattern6 = re.compile(r'^[A-Za-z0-9]+$') #Jumbled letters and numbers only in the entire line
pattern7 = re.compile(r'my_sucuri_encoding') # Legit sucuri file that look slike bad file
pattern8 = re.compile(r'\'.\'=>\'.\'') # Array map obfus
pattern9 = re.compile(r'chr\([0-9]+\)') # int to ascii
pattern12 = re.compile(r'gzinflate[\s\(]') # int to ascii
pattern15 = re.compile(r'\$[li]+[{=]')

def list_paths(root_tree, path=''):
    for blob in root_tree.blobs:
        yield blob.name if path == '' else f'{path}/{blob.name}'
    for tree in root_tree.trees:
        yield from list_paths(tree, tree.name if path == '' else f'{path}/{tree.name}')

def decode_file(path):
    output_path = f'{path}.decoded'
    with open(path, 'rb') as infile, open(output_path, 'wb') as outfile:
        for line in infile.readlines():
            try:
                decoded = base64.b64decode(line)
            except binascii.Error:
                outfile.write(line)
            else:
                try:
                    outfile.write(decoded)
                except UnicodeDecodeError:
                    outfile.write(line)
    return output_path

def main():
    # 1. Iterate all files in all commits
    # 2. Base-64 decode all files
    # 3. YODA
    directory_path = '/home/sai/web-malware/website-682886'
    repo = git.Repo(directory_path)
    repo.git.execute(['git', 'checkout', 'master'])
    repo.git.execute(['git', 'reset', '--hard', 'HEAD'])
    rows = []
    file_names_all_commits = []
    for commit in repo.iter_commits(reverse=True):
        repo.git.checkout(commit.hexsha)
        print(f'Commit: {commit.hexsha}')
        file_names = set()
        for file_path in list_paths(commit.tree, directory_path):
            file_names.add(file_path)
            output_path = decode_file(file_path)
            with open(output_path, 'r', encoding='ISO-8859-1') as file:
                comment_block = False
                r_data = file.read()
                p1 = re.findall(pattern1, r_data)
                #print("P1", p1)
                p2 = re.findall(pattern2, r_data)
                #print("P2", p2)
                p3 = re.findall(pattern3, r_data)
                #print("P3", p3)
                p4 = re.findall(pattern4, r_data)
                #print("P4", p4)
                p5 = re.findall(pattern5, r_data)
                #print("P5", p5)
                p6 = re.findall(pattern6, r_data)
                #print("P6", p6)
                p7 = re.findall(pattern7, r_data)
                #print("P7", p7)
                p8 = re.findall(pattern8, r_data)
                #print("P8", p8)
                p9 = re.findall(pattern9, r_data)
                #print("P9", p9)
                p12 = re.findall(pattern12, r_data)
                #print("P12", p12)
                p15 = re.findall(pattern15, r_data)
                #print("P15", p15)
                susp = False
                p10=None
                p11=None
                p13=None
                p14=None
                if len(p9) > 15 or p3 or (p3 and p5 and p12) or p15:
                    for current_line in file.readlines():
                        current_line = current_line.strip('\n').strip()
                        if comment_block == True:
                            if '*/' not in current_line:
                                continue
                            elif current_line.endswith('*/'):
                                comment_block = False
                                continue
                            elif '*/' in current_line:
                                comment_block = False

                        # Single line comments
                        if current_line.startswith('#') or current_line.startswith('//'):
                            continue
                        if current_line.startswith('/*') and current_line.endswith('*/'):
                            continue
                        # Multiline comment
                        if current_line.startswith('/*') and '*/' not in current_line:
                            comment_block = True
                            continue
                        p10 = re.findall(pattern9, current_line)
                        # Find base64_decde in line
                        p11 = re.findall(pattern3, current_line) #base64_decode
                        p13 = re.findall(pattern12, current_line) #gzinflate
                        p14 = re.findall(pattern5, current_line) #eval
                        p15 = re.findall(pattern15, current_line)
                        #print()
                        #print(p15)
                        if p11 and len(current_line) > 700:
                            susp = True 
                            break
                        if len(p15)>10 and len(current_line) > 1000:
                            susp = True 
                            break

                        if len(p10) > 15:
                            susp = True
                            break
                        if p11 and p13 and p14:
                            #print(p12, p13, p14)
                            susp = True
                            break

                # Test this p1 tested. Test the others
                if (len(p1) > 10) or (len(p2) > 10) or  (p3 and p4 and p5) or (len(p8)>10) or (susp) or (len(p4)>15) or len(p15)>10:
                    rows.append([commit.hexsha, file_path])
                elif p6:
                    if ((len(p6[0]) > 25) and (len(p6) > 30 ) and (len(p5)>0) and (len(p7)==0)):
                        rows.append([commit.hexsha, file_path])
        repo.git.execute(['git', 'clean', '-fx'])
        file_names_all_commits.append(file_names)

    with open('result.csv', 'w') as result:
        writer = csv.writer(result)
        writer.writerow(['Commit', 'File'])
        writer.writerows(rows)
    
    flagged_files = [row[1] for row in rows]
    with open('candidates.txt', 'w') as outfile:
        for common_file in set().union(*file_names_all_commits):
            if common_file in flagged_files:
                outfile.write(common_file + '\n')

if __name__ == '__main__':
    main()
